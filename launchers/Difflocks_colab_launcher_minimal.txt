# @title üöÄ DiffLocks Studio - Colab Edition (V67 - Correct Device Fix)
# ==================================================================================
# V67: Device fix in forward() instead of register_buffer to maintain checkpoint compatibility
# ==================================================================================

import os
import sys
import subprocess
import shutil
import time
import threading
import re
from pathlib import Path
import ipywidgets as widgets
from IPython.display import display, HTML, IFrame

# ==============================================================================
# CONFIGURATION
# ==============================================================================
if Path("/content").exists():
    WORK_DIR = Path("/content")
elif Path("/kaggle").exists():
    WORK_DIR = Path("/kaggle/working")
else:
    WORK_DIR = Path.cwd()

REPO_DIR = WORK_DIR / "DiffLocks-Studio"
OUTPUT_DIR = WORK_DIR / "outputs"
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
BLENDER_DIR = WORK_DIR / "blender"
APP_SCRIPT = WORK_DIR / "difflocks_runner.py"
CONSTRAINTS_FILE = WORK_DIR / "constraints.txt"
MARKER_FILE = WORK_DIR / f".difflocks_v67_{'colab' if Path('/content').exists() else 'kaggle' if Path('/kaggle').exists() else 'local'}_complete"

HF_REPO_ID = "arqdariogomez/difflocks-assets-hybrid"
MESHCAPADE_REPO = "https://github.com/Meshcapade/difflocks.git"

# Dynamic Checkpoint detection for Colab
def find_checkpoints_colab():
    # 1. Check Google Drive first (Persistence)
    gdrive_path = Path("/content/drive/MyDrive/DiffLocks/checkpoints")
    if gdrive_path.exists() and (gdrive_path / "difflocks_diffusion").exists():
        return gdrive_path
    
    # 2. Check local working directory
    local_ckpt = REPO_DIR / "checkpoints"
    if local_ckpt.exists() and (local_ckpt / "difflocks_diffusion").exists():
        return local_ckpt
        
    return None

# ==============================================================================
# UI
# ==============================================================================
main_output = widgets.Output()
display(main_output)
log_lines = []

def show_status(progress, message, status="running"):
    colors = {"running": "#818cf8", "success": "#34d399", "error": "#f87171", "warning": "#fbbf24"}
    color = colors.get(status, "#818cf8")
    logs_html = ""
    if log_lines:
        logs_content = "<br>".join(log_lines[-20:])
        logs_html = f'''<details style="margin-top:10px" open>
            <summary style="cursor:pointer;color:#a1a1aa;font-size:12px">üìã Logs ({len(log_lines)})</summary>
            <div style="background:#27272a;padding:10px;border-radius:5px;margin-top:5px;max-height:250px;overflow-y:auto;font-family:monospace;font-size:11px;color:#d4d4d8;border:1px solid #3f3f46">{logs_content}</div>
        </details>'''

    html = f'''<div style="background:linear-gradient(135deg,#18181b,#27272a);border-left:4px solid {color};border-radius:8px;padding:20px;margin:10px 0;border:1px solid #3f3f46">
        <div style="display:flex;justify-content:space-between;margin-bottom:10px">
            <span style="font-size:24px;font-weight:700;color:#fafafa">üíá‚Äç‚ôÄÔ∏è DiffLocks Studio</span>
            <span style="background:{color}33;color:{color};padding:4px 12px;border-radius:20px;font-size:12px;font-weight:600">{progress}%</span>
        </div>
        <div style="color:#e4e4e7;font-size:16px;margin-bottom:15px">{message}</div>
        <div style="background:#3f3f46;height:6px;border-radius:3px;overflow:hidden">
            <div style="width:{progress}%;height:100%;background:linear-gradient(90deg,{color},{color}cc)"></div>
        </div>
        {logs_html}
    </div>'''
    with main_output:
        main_output.clear_output(wait=True)
        display(widgets.HTML(html))

def log(msg, level="info"):
    icons = {"info": "‚ÑπÔ∏è", "success": "‚úÖ", "error": "‚ùå", "warning": "‚ö†Ô∏è"}
    ts = time.strftime('%H:%M:%S')
    log_lines.append(f"{icons.get(level, '‚ÑπÔ∏è')} [{ts}] {msg}")
    print(f"[{ts}] {msg}")

def show_gradio_frame(url):
    with main_output:
        main_output.clear_output(wait=True)
        display(HTML(f'''
            <div style="background:linear-gradient(135deg,#18181b,#27272a);border:1px solid #34d399;border-radius:12px;padding:15px;margin-bottom:10px">
                <div style="display:flex;align-items:center;gap:10px;margin-bottom:10px">
                    <span style="font-size:28px">‚úÖ</span>
                    <span style="font-size:20px;font-weight:700;color:#34d399">DiffLocks Studio Ready!</span>
                </div>
                <p style="color:#a1a1aa;margin:5px 0">Public URL: <a href="{url}" target="_blank" style="color:#818cf8">{url}</a></p>
                <p style="color:#71717a;font-size:12px">If the iframe doesn't load, click the link above.</p>
            </div>
        '''))
        display(IFrame(src=url, width="100%", height=850))

# ==============================================================================
# HELPERS
# ==============================================================================
def run_cmd(cmd, timeout=600, cwd=None, env=None):
    try:
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True,
                               timeout=timeout, cwd=cwd or str(WORK_DIR), env=env)
        return result.returncode == 0, result.stdout, result.stderr
    except subprocess.TimeoutExpired:
        return False, "", "timeout"
    except Exception as e:
        return False, "", str(e)

def get_pkg_version_subprocess(pkg):
    try:
        result = subprocess.run([sys.executable, "-c", f"import {pkg}; print({pkg}.__version__)"],
                               capture_output=True, text=True, timeout=30)
        if result.returncode == 0:
            return result.stdout.strip()
    except:
        pass
    return None

def check_gpu():
    try:
        result = subprocess.run(["nvidia-smi", "--query-gpu=name,memory.total", "--format=csv,noheader"],
                               capture_output=True, text=True, timeout=10)
        if result.returncode == 0 and result.stdout.strip():
            return True, result.stdout.strip().split(',')[0].strip()
    except:
        pass
    return False, None

def get_hf_token():
    try:
        from google.colab import userdata
        return userdata.get('HF_TOKEN')
    except:
        return os.environ.get('HF_TOKEN')

# ==============================================================================
# üîß DEVICE FIXES - Applied to source files after cloning
# ==============================================================================
def apply_device_fixes():
    """
    Apply device fixes to repository source files.
    Uses .to(z.device) in forward() instead of register_buffer to maintain checkpoint compatibility.
    """
    fixes_applied = 0

    # =========================================================================
    # FIX 1: models/strand_codec.py
    # Move t to z.device in forward(), NOT using register_buffer
    # =========================================================================
    strand_codec_path = REPO_DIR / "models/strand_codec.py"
    if strand_codec_path.exists():
        content = strand_codec_path.read_text()
        original = content

        # Revert any register_buffer changes if they exist (from previous V66 run)
        content = content.replace(
            "self.register_buffer('t', torch.linspace(",
            "self.t = torch.linspace("
        )
        content = content.replace(
            "self.register_buffer('start_positions', torch.zeros(",
            "self.start_positions = torch.zeros("
        )

        # Now apply the correct fix: add .to(z.device) where t is used
        # Pattern: t = self.t.view(...).repeat(...)
        # We need to add .to(z.device) at the end

        # Find the line that creates t from self.t and add .to(z.device)
        lines = content.split('\n')
        modified_lines = []

        for i, line in enumerate(lines):
            # Pattern 1: t = self.t.view(1, self.nr_verts_to_create, -1).repeat(nr_strands, 1, 1)
            if 'self.t.view' in line and '.repeat(' in line and '.to(' not in line:
                # Add .to(z.device) at the end before any comment
                stripped = line.rstrip()
                if stripped.endswith(')'):
                    # Find the indentation
                    indent = len(line) - len(line.lstrip())
                    # Append .to(z.device)
                    new_line = stripped + '.to(z.device)'
                    modified_lines.append(' ' * indent + new_line.lstrip())
                    log(f"Fixed line {i+1}: added .to(z.device) to t tensor", "info")
                    continue

            # Pattern 2: Also fix start_positions if used with cat
            if 'self.start_positions' in line and '.repeat(' in line and '.to(' not in line:
                stripped = line.rstrip()
                if stripped.endswith(')'):
                    indent = len(line) - len(line.lstrip())
                    new_line = stripped + '.to(z.device)'
                    modified_lines.append(' ' * indent + new_line.lstrip())
                    log(f"Fixed line {i+1}: added .to(z.device) to start_positions", "info")
                    continue

            modified_lines.append(line)

        content = '\n'.join(modified_lines)

        if content != original:
            strand_codec_path.write_text(content)
            fixes_applied += 1
            log("Fixed strand_codec.py: added .to(z.device) for tensor compatibility", "success")

    # =========================================================================
    # FIX 2: utils/strand_util.py - time_pts device (if used with CUDA tensors)
    # =========================================================================
    strand_util_path = REPO_DIR / "utils/strand_util.py"
    if strand_util_path.exists():
        content = strand_util_path.read_text()
        original = content

        # Pattern: time_pts = torch.arange(nr_verts_per_strand) / (nr_verts_per_strand - 1)
        # This is in a function where strand_latent is a parameter, so we can use its device

        # Fix: Add device parameter
        old_patterns = [
            "time_pts = torch.arange(nr_verts_per_strand) / (nr_verts_per_strand - 1)",
            "time_pts = torch.arange(nr_verts_per_strand).float() / (nr_verts_per_strand - 1)",
            "time_pts = torch.arange(nr_verts_per_strand, device=points.device) / (nr_verts_per_strand - 1)"
        ]

        for old_pattern in old_patterns:
            if old_pattern in content:
                # If it already has device=points.device, it's fine, but let's make it more robust
                if "device=" not in old_pattern or "points.device" in old_pattern:
                    new_pattern = "time_pts = torch.arange(nr_verts_per_strand, device=points.device if 'points' in locals() else (strand_latent.device if 'strand_latent' in locals() else 'cpu')) / (nr_verts_per_strand - 1)"
                    content = content.replace(old_pattern, new_pattern)

        if content != original:
            strand_util_path.write_text(content)
            fixes_applied += 1
            log("Fixed strand_util.py: time_pts device", "success")

    log(f"Applied {fixes_applied} device fixes", "success")
    return fixes_applied

# ==============================================================================
# INSTALLATION
# ==============================================================================
def install():
    WORK_DIR.mkdir(exist_ok=True)
    OUTPUT_DIR.mkdir(exist_ok=True)

    show_status(2, "üìù Creating constraints...")
    CONSTRAINTS_FILE.write_text("numpy>=1.26.0,<2.0.0\n")

    show_status(5, "üì¶ System dependencies...")
    run_cmd("apt-get update -qq && apt-get install -y -qq xz-utils libxrender1 libsm6 libgl1-mesa-glx libglib2.0-0 git-lfs > /dev/null 2>&1")
    log("System packages ready", "success")

    show_status(8, "üì• Cloning repository...")
    if REPO_DIR.exists():
        shutil.rmtree(REPO_DIR)

    success, _, _ = run_cmd(f"git clone --depth 1 https://github.com/arqdariogomez/DiffLocks-Studio.git {REPO_DIR}", timeout=120)
    if not success:
        raise Exception("Failed to clone repository")
    log("Repository cloned", "success")

    # =========================================================================
    # APPLY DEVICE FIXES
    # =========================================================================
    show_status(10, "üîß Applying device compatibility fixes...")
    apply_device_fixes()

    show_status(12, "üßπ Cleaning environment...")
    # Explicitly uninstall to avoid binary conflicts
    run_cmd("pip uninstall -y numpy scipy pandas matplotlib gradio natten 2>/dev/null || true")
    run_cmd("pip cache purge 2>/dev/null || true")

    site_packages = subprocess.run([sys.executable, "-c", "import site; print(site.getsitepackages()[0])"],
                                   capture_output=True, text=True).stdout.strip()
    # Deep clean of package directories to remove any leftover .so files
    for pkg in ["numpy", "numpy.libs", "scipy", "scipy.libs", "pandas", "pandas.libs", "matplotlib", "matplotlib.libs", "gradio"]:
        pkg_path = Path(site_packages) / pkg
        if pkg_path.exists():
            shutil.rmtree(pkg_path, ignore_errors=True)
        for dist in Path(site_packages).glob(f"{pkg}*.dist-info"):
            shutil.rmtree(dist, ignore_errors=True)
    log("Cleaned numpy/scipy/pandas/gradio", "success")

    show_status(18, "üî• Installing Core Stack (NumPy 1.26.4)...")
    # Install numpy first and separately to ensure it's the base
    run_cmd("pip install --no-cache-dir numpy==1.26.4", timeout=120)
    
    # Then install the rest, ensuring they are compatible
    core_deps = ["pandas==2.2.2", "matplotlib", "gradio==3.50.2"]
    run_cmd(f"pip install --no-cache-dir {' '.join(core_deps)}", timeout=300)

    show_status(35, "üî¨ Installing SciPy 1.13.1...")
    run_cmd(f"pip install --no-cache-dir scipy==1.13.1", timeout=300)
    
    # Critical: Force reload of numpy to avoid 'dtype size changed' error
    import importlib
    import numpy
    importlib.reload(numpy)
    
    log(f"SciPy: {get_pkg_version_subprocess('scipy')}", "success")
    
    torch_ver = get_pkg_version_subprocess("torch")
    if not torch_ver or not torch_ver.startswith("2.4"):
        run_cmd(f"pip install --no-cache-dir torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cu121", timeout=600)
    
    log(f"Core Stack: NumPy {get_pkg_version_subprocess('numpy')}, PyTorch {get_pkg_version_subprocess('torch')}", "success")

    show_status(42, "üß© Installing NATTEN...")
    env = os.environ.copy()
    env['PYTHONHTTPSVERIFY'] = '0'
    run_cmd(f"pip install --no-cache-dir -c {CONSTRAINTS_FILE} --trusted-host shi-labs.com natten==0.17.1+torch240cu121 -f https://shi-labs.com/natten/wheels/", timeout=600, env=env)
    log("NATTEN installed", "success")

    show_status(50, "üìö Installing dependencies...")
    deps = ["huggingface_hub", "accelerate", "safetensors", "einops",
            "dctorch", "torchdiffeq", "torchsde", "libigl", "trimesh", "mediapipe",
            "plotly", "hjson", "jsonmerge", "Pillow", "opencv-contrib-python"]
    run_cmd(f"pip install --no-cache-dir -c {CONSTRAINTS_FILE} {' '.join(deps)}", timeout=300)
    log("Dependencies installed", "success")

    show_status(58, "üîç Verifying NumPy...")
    np_ver = get_pkg_version_subprocess("numpy")
    if not np_ver or not np_ver.startswith("1.26"):
        log(f"NumPy was upgraded to {np_ver}! Fixing...", "warning")
        run_cmd("pip uninstall -y numpy scipy", timeout=60)
        run_cmd("pip install --no-cache-dir numpy==1.26.4", timeout=120)
        run_cmd(f"pip install --no-cache-dir -c {CONSTRAINTS_FILE} scipy==1.13.1", timeout=300)
    log(f"Verified NumPy: {get_pkg_version_subprocess('numpy')}", "success")

    show_status(62, "üß† Setting up checkpoints...")
    ckpt_dir = REPO_DIR / "checkpoints"
    
    current_ckpts = find_checkpoints_colab()
    if current_ckpts:
        if current_ckpts != ckpt_dir:
            if ckpt_dir.exists() and not ckpt_dir.is_symlink():
                shutil.rmtree(ckpt_dir)
            if not ckpt_dir.exists():
                ckpt_dir.symlink_to(current_ckpts)
            log(f"Checkpoints linked from {current_ckpts}", "success")
        else:
            log("Checkpoints already present", "success")
    else:
        log("Checkpoints not found. Checking for Google Drive mount...", "info")
        if not Path("/content/drive").exists():
            from google.colab import drive
            try:
                drive.mount('/content/drive', force_remount=True)
            except:
                log("Google Drive mount skipped or failed", "warning")
        
        # Check again after mount
        current_ckpts = find_checkpoints_colab()
        if current_ckpts:
            if not ckpt_dir.exists():
                ckpt_dir.symlink_to(current_ckpts)
            log("Checkpoints linked from Google Drive", "success")
        else:
            log("Still no checkpoints. Asking for Meshcapade login...", "info")
            # In Colab we can use input() or a widget
            # Let's try to get them from environment first (if user set them)
            mesh_user = os.environ.get("MESH_USER")
            mesh_pass = os.environ.get("MESH_PASS")
            
            if not mesh_user or not mesh_pass:
                # We show a simple input form
                print("\nüîê MESH CAPADE LOGIN REQUIRED")
                print("Create an account at https://meshcapade.com if you don't have one.")
                mesh_user = input("Username/Email: ").strip()
                mesh_pass = input("Password: ").strip()
            
            if mesh_user and mesh_pass:
                os.environ["MESH_USER"] = mesh_user
                os.environ["MESH_PASS"] = mesh_pass
                log("Downloading official checkpoints from Meshcapade...", "info")
                run_cmd(f"cd {REPO_DIR} && python download_checkpoints.py --meshcapade", timeout=600)
                
                # Ask to save to Drive for next time
                if Path("/content/drive/MyDrive").exists():
                    save_to_drive = input("Do you want to save these checkpoints to Google Drive for next time? (y/n): ").lower() == 'y'
                    if save_to_drive:
                        gdrive_dest = Path("/content/drive/MyDrive/DiffLocks/checkpoints")
                        gdrive_dest.parent.mkdir(parents=True, exist_ok=True)
                        log(f"Copying checkpoints to {gdrive_dest}...", "info")
                        shutil.copytree(ckpt_dir, gdrive_dest, dirs_exist_ok=True)
                        log("Checkpoints saved to Google Drive!", "success")
            else:
                log("No credentials provided. Fallback to generic download...", "warning")
                run_cmd(f"cd {REPO_DIR} && python download_checkpoints.py", timeout=600)

    show_status(70, "üîç Post-download verification...")
    np_ver = get_pkg_version_subprocess("numpy")
    if not np_ver or not np_ver.startswith("1.26"):
        run_cmd("pip uninstall -y numpy scipy", timeout=60)
        run_cmd("pip install --no-cache-dir numpy==1.26.4", timeout=120)
        run_cmd(f"pip install --no-cache-dir -c {CONSTRAINTS_FILE} scipy==1.13.1", timeout=300)
    log(f"Final: NumPy {get_pkg_version_subprocess('numpy')}, SciPy {get_pkg_version_subprocess('scipy')}", "success")

    show_status(74, "üì± MediaPipe task...")
    task_path = REPO_DIR / "inference/assets/face_landmarker_v2_with_blendshapes.task"
    task_path.parent.mkdir(parents=True, exist_ok=True)
    if not task_path.exists() or task_path.stat().st_size < 1000000:
        run_cmd(f"wget -q -O {task_path} https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task", timeout=120)
    log("MediaPipe task ready", "success")

    show_status(78, "üîç Getting scalp.ply...")
    scalp_path = REPO_DIR / "inference/assets/scalp.ply"
    if not scalp_path.exists() or scalp_path.stat().st_size < 100:
        meshcapade_dir = WORK_DIR / "meshcapade_temp"
        if meshcapade_dir.exists():
            shutil.rmtree(meshcapade_dir)
        run_cmd("git lfs install")
        run_cmd(f"git clone --filter=blob:none --sparse {MESHCAPADE_REPO} {meshcapade_dir}", timeout=120)
        if meshcapade_dir.exists():
            run_cmd("git sparse-checkout set data_loader/difflocks_bodydata", cwd=str(meshcapade_dir))
            run_cmd("git lfs pull", cwd=str(meshcapade_dir), timeout=300)
            for name in ["scalp.ply", "smplx_base.ply"]:
                src = meshcapade_dir / "data_loader/difflocks_bodydata" / name
                if src.exists():
                    for dst_dir in [REPO_DIR / "inference/assets", REPO_DIR / "data_loader/difflocks_bodydata"]:
                        dst_dir.mkdir(parents=True, exist_ok=True)
                        shutil.copy2(str(src), str(dst_dir / name))
                    log(f"{name}: {src.stat().st_size / 1024:.1f} KB", "success")
            shutil.rmtree(meshcapade_dir, ignore_errors=True)
    else:
        log("scalp.ply exists", "success")

    show_status(85, "üé® Installing Blender...")
    blender_exe = BLENDER_DIR / "blender"
    if not blender_exe.exists():
        if BLENDER_DIR.exists():
            shutil.rmtree(BLENDER_DIR)
        BLENDER_DIR.mkdir(exist_ok=True)
        run_cmd("wget -q -O /tmp/blender.tar.xz 'https://download.blender.org/release/Blender4.2/blender-4.2.5-linux-x64.tar.xz'", timeout=300)
        run_cmd(f"tar -xf /tmp/blender.tar.xz -C {BLENDER_DIR} --strip-components=1", timeout=120)
        Path("/tmp/blender.tar.xz").unlink(missing_ok=True)
    log("Blender ready", "success")

    show_status(90, "‚úÖ Final verification...")
    log(f"NumPy: {get_pkg_version_subprocess('numpy')}", "info")
    log(f"SciPy: {get_pkg_version_subprocess('scipy')}", "info")
    log(f"PyTorch: {get_pkg_version_subprocess('torch')}", "info")
    log(f"NATTEN: {get_pkg_version_subprocess('natten')}", "info")

    MARKER_FILE.write_text(f"v67 - {time.strftime('%Y-%m-%d %H:%M:%S')}")
    show_status(95, "‚úÖ Installation complete!", "success")
    return True

# ==============================================================================
# 5. RUN APP
# ==============================================================================
def main():
    log("DiffLocks Studio V67 - Universal Launcher", "info")

    gpu_ok, gpu_name = check_gpu()
    if not gpu_ok:
        with main_output:
            main_output.clear_output(wait=True)
            display(HTML('''<div style="background:linear-gradient(135deg,#450a0a,#7f1d1d);border:2px solid #f87171;border-radius:12px;padding:30px;text-align:center">
                <span style="font-size:48px">‚ö†Ô∏è</span><h2 style="color:#fca5a5">GPU Required</h2>
                <p style="color:#fecaca">Runtime ‚Üí Change runtime type ‚Üí T4 GPU</p></div>'''))
        return

    log(f"GPU: {gpu_name}", "success")

    if not MARKER_FILE.exists():
        install()
    else:
        log("Using cached installation", "success")
        show_status(95, "üîß Verifying fixes...")
        apply_device_fixes()
        show_status(95, "‚úÖ Ready", "success")

    np_ver = get_pkg_version_subprocess("numpy")
    if not np_ver or not np_ver.startswith("1.26"):
        log(f"NumPy is {np_ver}, fixing...", "warning")
        run_cmd("pip uninstall -y numpy scipy", timeout=60)
        run_cmd("pip install --no-cache-dir numpy==1.26.4", timeout=120)
        run_cmd(f"pip install --no-cache-dir -c {CONSTRAINTS_FILE} scipy==1.13.1", timeout=300)

    show_status(98, "üöÄ Launching...")
    
    # Add REPO_DIR to sys.path
    if str(REPO_DIR) not in sys.path:
        sys.path.insert(0, str(REPO_DIR))
    
    # Import the demo from app.py
    try:
        os.chdir(REPO_DIR)
        # Clear cache to avoid import issues
        for m in list(sys.modules.keys()):
            if m.startswith('app') or m.startswith('inference'):
                del sys.modules[m]
        
        from app import demo
        
        # Render final status
        show_status(100, "üöÄ Starting Gradio Interface...", "success")
        log("Launching app.py logic...", "success")
        
        # Limpiar consola antes de lanzar para una UI m√°s limpia
        from IPython.display import clear_output
        import contextlib
        import io

        clear_output(wait=True)
        
        # Launch the demo with output suppression to avoid showing Gradio boilerplate
        # app.py handles the platform-specific launch_kwargs via __main__
        # but since we are importing it, we call launch here with the right parameters for Colab
        
        # We wrap the launch in a way that if it fails early, we see the error
        try:
            # We don't suppress stdout here initially to see if it starts
            # with contextlib.redirect_stdout(io.StringIO()):
            #     with contextlib.redirect_stderr(io.StringIO()):
            demo.queue().launch(share=True, inline=True, height=1000, quiet=False)
        except Exception as launch_err:
            log(f"Gradio Launch Error: {launch_err}", "error")
            raise launch_err
        
    except Exception as e:
        show_status(0, f"‚ùå Launch Error: {e}", "error")
        import traceback
        log(traceback.format_exc(), "error")
        raise

try:
    main()
except Exception as e:
    import traceback
    log(f"Fatal: {e}", "error")
    print(traceback.format_exc())
    show_status(0, f"‚ùå {str(e)[:60]}", "error")