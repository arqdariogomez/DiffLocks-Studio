services:
  difflocks:
    build: .
    container_name: difflocks_studio
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - HF_TOKEN=${HF_TOKEN:-} # Optional: Pass HF_TOKEN from host environment
      - TORCH_HOME=/app/.cache/torch # Store PyTorch cache in persistent volume
    ports:
      - "7860:7860"
    volumes:
      - .:/app
      - /app/blender # Preserve blender folder from image
      - /app/inference/assets # Preserve assets from image
      - ./checkpoints:/app/checkpoints
      - ./studio_outputs:/app/studio_outputs
      - ./torch_cache:/app/.cache/torch # Persistent volume for PyTorch cache
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [ gpu ]
    command: ["bash", "-c", "mkdir -p /app/.cache/torch/hub && chmod -R 777 /app/.cache && python app.py"]

volumes:
  torch_cache:
